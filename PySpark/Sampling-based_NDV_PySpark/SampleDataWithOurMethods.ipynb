{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f4aee0bb588>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "memory = '200g'\n",
    "pyspark_submit_args = ' --driver-memory ' + memory  +' pyspark-shell' +\" --num-executors 15 --executor-cores 8\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from HyperLogLog import Hyperloglog as hll\n",
    "from HyperLogLog import Countsketch\n",
    "from HyperLogLog import Data2sketch\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc=SparkContext(master=\"spark://Master:17077\",appName=\"test\")\n",
    "#sc=SparkContext(appName=\"test\")\n",
    "sc._conf.set(\"spark.driver.maxResultSize\", '50g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransData(partition):\n",
    "    level=1\n",
    "    D2S=Data2sketch(width,level)\n",
    "    D2S.ScanString([item.encode(\"utf-8\") for item in partition])\n",
    "    Item=[item.encode(\"utf-8\") for item in partition]\n",
    "    yield [[D2S.fiArray(i) for i in range(level)],D2S.NDVArray()]\n",
    "def part2sketch(ss):\n",
    "    level=1\n",
    "    NDV=hll(width)\n",
    "    hllarray=[hll(width) for i in range(level)]\n",
    "    for item in ss:\n",
    "        for ele in item:\n",
    "            if ele[1]<=level:\n",
    "                hllarray[ele[1]-1].add(str(ele[0]).encode(\"utf-8\"))\n",
    "            NDV.add(str(ele[0]).encode(\"utf-8\"))\n",
    "    data=[[h.Array() for h in hllarray],NDV.Array()]\n",
    "    yield data\n",
    "def GEE(NDV,f1,q):\n",
    "    return f1*(math.sqrt(1/q)-1)+NDV\n",
    "def ModifyChao(NDV,f1):\n",
    "    return NDV+f1*(f1-1)/2/(NDV-f1+1)\n",
    "def partComputef1(ss):\n",
    "    sketch=pickle.loads(b.value)\n",
    "    f1=0\n",
    "    for s in ss:\n",
    "        f1t=Computef1(sketch,s)\n",
    "        f1+=f1t\n",
    "    yield f1\n",
    "def Computef1(SKList,F1ID):\n",
    "    k_mechine=len(SKList)\n",
    "    ZeroSketch=hll(width)\n",
    "    IntersetID=[]\n",
    "    for i in range(k_mechine):\n",
    "        if i!=F1ID:\n",
    "            ZeroSketch.update(SKList[i][1])\n",
    "    MergeSketch=hll(width)\n",
    "    MergeSketch.update(SKList[F1ID][0][0])\n",
    "    f1=MergeSketch.estimate()\n",
    "    MergeSketch.update(ZeroSketch.Array())\n",
    "    f1pure=MergeSketch.estimate()-ZeroSketch.estimate()\n",
    "    return f1pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'444087624'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1rdd=sc.textFile('/user/poi/poi-50-1kww/')\n",
    "file1rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count n time: 29.21687078475952\n",
      "n: 1000032019\n"
     ]
    }
   ],
   "source": [
    "begin=time.time()\n",
    "n=file1rdd.count()\n",
    "end=time.time()\n",
    "print(\"count n time:\",end-begin)\n",
    "print(\"n:\",n)\n",
    "width=16\n",
    "q=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect Time: 39.35223722457886\n"
     ]
    }
   ],
   "source": [
    "begin=time.time()\n",
    "part_dict = file1rdd.mapPartitions(TransData)\n",
    "a=part_dict.collect()\n",
    "end=time.time()\n",
    "print(\"Collect Time:\",end-begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Computef1(SKList,F1ID):\n",
    "    k_mechine=len(SKList)\n",
    "    ZeroSketch=hll(width)\n",
    "    IntersetID=[]\n",
    "    for i in range(k_mechine):\n",
    "        if i!=F1ID:\n",
    "            ZeroSketch.update(SKList[i][1])\n",
    "    MergeSketch=hll(width)\n",
    "    MergeSketch.update(SKList[F1ID][0][0])\n",
    "    f1=MergeSketch.estimate()\n",
    "    MergeSketch.update(ZeroSketch.Array())\n",
    "    f1pure=MergeSketch.estimate()-ZeroSketch.estimate()\n",
    "    return f1pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVSketch=[[]]\n",
    "UniqueSketch=[]\n",
    "times=1\n",
    "for sk in SKList:\n",
    "    temp=hll(width)\n",
    "    temp.update(sk[1])\n",
    "    UniqueSketch.append(temp)\n",
    "    level=0\n",
    "    temp=hll(width)\n",
    "    temp.update(sk[0][0])\n",
    "    NDVSketch[level].append(temp)\n",
    "    level+=1\n",
    "    m=times\n",
    "    for level in range(1,len(NDVSketch)):\n",
    "        if m==2**level*len(NDVSketch[level]):\n",
    "            NDVSketch[level][-1].update(NDVSketch[level-1][-2].Array())\n",
    "            NDVSketch[level][-1].update(NDVSketch[level-1][-1].Array())\n",
    "        if m==2**level*len(NDVSketch[level])+1:\n",
    "            temp=hll(width)\n",
    "            NDVSketch[level].append(temp)\n",
    "        if len(NDVSketch[-1])==3:\n",
    "            NDVSketch.append([])\n",
    "            temp=hll(width)\n",
    "            NDVSketch[-1].append(temp)\n",
    "            NDVSketch[-1][0].update(NDVSketch[-2][0].Array())\n",
    "            NDVSketch[-1][0].update(NDVSketch[-2][1].Array())\n",
    "            NDVSketch[-1].append([])\n",
    "        times+=1\n",
    "def query(NDVSketch,index,UniqueSketch):\n",
    "    level=len(NDVSketch)-1\n",
    "    result=hll(width)\n",
    "    base=0\n",
    "    esti=0\n",
    "    if index<2**level:\n",
    "        # left\n",
    "        level-=1\n",
    "        base=0\n",
    "        while level>=0:\n",
    "            if index<(base+1)*2**level:\n",
    "                result.update(NDVSketch[level][base+1].Array())\n",
    "                base=base*2\n",
    "            else:\n",
    "                result.update(NDVSketch[level][base].Array())\n",
    "                base=(base+1)*2\n",
    "            level-=1\n",
    "        # right\n",
    "        machine=len(NDVSketch[0])\n",
    "        level=0\n",
    "        while 2**level<=len(NDVSketch[0])-2**(len(NDVSketch)-1):\n",
    "            #print(level,machine,ndv[level][machine-1])\n",
    "            if machine%2==0 and machine//2!=1:\n",
    "                machine=machine//2\n",
    "            else:\n",
    "                result.update(NDVSketch[level][machine-1].Array())\n",
    "                machine=(machine-1)//2\n",
    "            level+=1\n",
    "        #result.append([-NDVSketch[0][index][0]])\n",
    "    else:\n",
    "        #left\n",
    "        result.update(NDVSketch[-1][0].Array())\n",
    "        #right\n",
    "        machine=len(NDVSketch[0])\n",
    "        level=0\n",
    "        while 2**level<=len(NDVSketch[0])-2**(len(NDVSketch)-1):\n",
    "            #print(level,machine,ndv[level][machine-1])\n",
    "            if machine%2==0 and machine//2!=1:\n",
    "                machine=machine//2\n",
    "            else:\n",
    "                if index>machine*2**level-2**level-1 and index<=machine*2**level-1:\n",
    "                    tempindex=index\n",
    "                    for newlevel in range(level):\n",
    "                        result.update(ndv[newlevel][tempindex^1].Array())\n",
    "                        tempindex=tempindex//2\n",
    "                else:\n",
    "                    result.update(ndv[level][machine-1].Array())\n",
    "                machine=(machine-1)//2\n",
    "            level+=1\n",
    "        #result.append([-NDVSketch[0][index][0]])\n",
    "    esti-=result.estimate()\n",
    "    result.update(UniqueSketch[index].Array())\n",
    "    esti+=result.estimate()\n",
    "    return esti\n",
    "f1=0\n",
    "for index in range(len(SKList)):\n",
    "    f1+=query(NDVSketch,index,UniqueSketch)\n",
    "NDVhll=hll(width)\n",
    "for i in a:\n",
    "    NDVhll.update(i[1])\n",
    "NDV=NDVhll.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEE Time: 2.945502758026123\n",
      "Chao Time 2.946061611175537\n",
      "Shlosser Time: 21.31751537322998\n",
      "d: 787267195.931828\n",
      "f1: 605086523.0236659\n",
      "GEE: 6233045903.144821\n",
      "Chao: 1792120487.6820552\n",
      "Shlosser: 48051914003.0267\n"
     ]
    }
   ],
   "source": [
    "#NDVhll=hll(width)\n",
    "#for i in a:\n",
    "#    NDVhll.update(i[1])\n",
    "#NDV=NDVhll.estimate()\n",
    "#Part_num=len(a)\n",
    "#b=sc.broadcast(pickle.dumps(a))\n",
    "#begin=time.time()\n",
    "#Aimrdd=sc.parallelize([i for i in range(Part_num)])\n",
    "#result=Aimrdd.mapPartitions(partComputef1).collect()\n",
    "#f1=sum(result)\n",
    "\n",
    "DGEE=GEE(NDV,f1,q)\n",
    "end=time.time()\n",
    "print(\"GEE Time:\",end-begin)\n",
    "DChao=ModifyChao(NDV,f1)\n",
    "chend=time.time()\n",
    "print(\"Chao Time\",chend-begin)\n",
    "resapfi = sc.parallelize(file1rdd.take(int(n*q))).map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\\\n",
    "    .map(lambda d:(d[1],1)).reduceByKey(lambda e,f:e+f).collect()\n",
    "sampleNDV=0\n",
    "samplef1=0\n",
    "for (key,value) in resapfi:\n",
    "    sampleNDV+=value\n",
    "    if key==1:\n",
    "        samplef1=value\n",
    "DShlosser=NDV+f1*(NDV-sampleNDV)/samplef1\n",
    "shend=time.time()\n",
    "print(\"Shlosser Time:\",end-begin+shend-chend)\n",
    "print(\"d:\",NDV)\n",
    "print(\"f1:\",f1)\n",
    "print(\"GEE:\",DGEE)\n",
    "print(\"Chao:\",DChao)\n",
    "print(\"Shlosser:\",DShlosser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count n time: 79.08543157577515\n",
      "n: 5000084437\n",
      "Collect Time: 131.16143321990967\n",
      "GEE Time: 11.32073426246643\n",
      "Chao Time 11.321361780166626\n",
      "Shlosser Time: 74.56890630722046\n",
      "d: 3971129021.0032535\n",
      "f1: 3104075342.728803\n",
      "GEE: 31907807105.56248\n",
      "Chao: 9527465358.96543\n",
      "Shlosser: 248602678803.78427\n"
     ]
    }
   ],
   "source": [
    "file1rdd=sc.textFile('/user/poi/poi-50-5kww/')\n",
    "begin=time.time()\n",
    "n=file1rdd.count()\n",
    "end=time.time()\n",
    "print(\"count n time:\",end-begin)\n",
    "print(\"n:\",n)\n",
    "width=16\n",
    "q=0.01\n",
    "begin=time.time()\n",
    "part_dict = file1rdd.mapPartitions(TransData)\n",
    "a=part_dict.collect()\n",
    "end=time.time()\n",
    "print(\"Collect Time:\",end-begin)\n",
    "NDVhll=hll(width)\n",
    "for i in a:\n",
    "    NDVhll.update(i[1])\n",
    "NDV=NDVhll.estimate()\n",
    "Part_num=len(a)\n",
    "b=sc.broadcast(pickle.dumps(a))\n",
    "begin=time.time()\n",
    "Aimrdd=sc.parallelize([i for i in range(Part_num)])\n",
    "result=Aimrdd.mapPartitions(partComputef1).collect()\n",
    "f1=sum(result)\n",
    "DGEE=GEE(NDV,f1,q)\n",
    "end=time.time()\n",
    "print(\"GEE Time:\",end-begin)\n",
    "DChao=ModifyChao(NDV,f1)\n",
    "chend=time.time()\n",
    "print(\"Chao Time\",chend-begin)\n",
    "resapfi = sc.parallelize(file1rdd.take(int(n*q))).map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\\\n",
    "    .map(lambda d:(d[1],1)).reduceByKey(lambda e,f:e+f).collect()\n",
    "sampleNDV=0\n",
    "samplef1=0\n",
    "for (key,value) in resapfi:\n",
    "    sampleNDV+=value\n",
    "    if key==1:\n",
    "        samplef1=value\n",
    "DShlosser=NDV+f1*(NDV-sampleNDV)/samplef1\n",
    "shend=time.time()\n",
    "print(\"Shlosser Time:\",end-begin+shend-chend)\n",
    "print(\"d:\",NDV)\n",
    "print(\"f1:\",f1)\n",
    "print(\"GEE:\",DGEE)\n",
    "print(\"Chao:\",DChao)\n",
    "print(\"Shlosser:\",DShlosser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count n time: 154.47623562812805\n",
      "n: 9999969413\n",
      "Collect Time: 237.5415985584259\n",
      "GEE Time: 26.209994316101074\n",
      "Chao Time 26.21020269393921\n",
      "Shlosser Time: 134.90034532546997\n",
      "d: 7925433568.293607\n",
      "f1: 6156811768.681699\n",
      "GEE: 63336739486.4289\n",
      "Chao: 18641780934.27819\n",
      "Shlosser: 492107899737.4306\n"
     ]
    }
   ],
   "source": [
    "file1rdd=sc.textFile('/user/poi/poi-50-1www/')\n",
    "begin=time.time()\n",
    "n=file1rdd.count()\n",
    "end=time.time()\n",
    "print(\"count n time:\",end-begin)\n",
    "print(\"n:\",n)\n",
    "width=16\n",
    "q=0.01\n",
    "begin=time.time()\n",
    "part_dict = file1rdd.mapPartitions(TransData)\n",
    "a=part_dict.collect()\n",
    "end=time.time()\n",
    "print(\"Collect Time:\",end-begin)\n",
    "NDVhll=hll(width)\n",
    "for i in a:\n",
    "    NDVhll.update(i[1])\n",
    "NDV=NDVhll.estimate()\n",
    "Part_num=len(a)\n",
    "b=sc.broadcast(pickle.dumps(a))\n",
    "begin=time.time()\n",
    "Aimrdd=sc.parallelize([i for i in range(Part_num)])\n",
    "result=Aimrdd.mapPartitions(partComputef1).collect()\n",
    "f1=sum(result)\n",
    "DGEE=GEE(NDV,f1,q)\n",
    "end=time.time()\n",
    "print(\"GEE Time:\",end-begin)\n",
    "DChao=ModifyChao(NDV,f1)\n",
    "chend=time.time()\n",
    "print(\"Chao Time\",chend-begin)\n",
    "resapfi = sc.parallelize(file1rdd.take(int(n*q))).map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\\\n",
    "    .map(lambda d:(d[1],1)).reduceByKey(lambda e,f:e+f).collect()\n",
    "sampleNDV=0\n",
    "samplef1=0\n",
    "for (key,value) in resapfi:\n",
    "    sampleNDV+=value\n",
    "    if key==1:\n",
    "        samplef1=value\n",
    "DShlosser=NDV+f1*(NDV-sampleNDV)/samplef1\n",
    "shend=time.time()\n",
    "print(\"Shlosser Time:\",end-begin+shend-chend)\n",
    "print(\"d:\",NDV)\n",
    "print(\"f1:\",f1)\n",
    "print(\"GEE:\",DGEE)\n",
    "print(\"Chao:\",DChao)\n",
    "print(\"Shlosser:\",DShlosser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count n time: 25.738985776901245\n",
      "n: 999590784\n",
      "Collect Time: 41.590043783187866\n",
      "GEE Time: 3.0444674491882324\n",
      "Chao Time 3.0446937084198\n",
      "Shlosser Time: 19.73644208908081\n",
      "d: 982111665.846918\n",
      "f1: 970160533.4956743\n",
      "GEE: 9713556467.307987\n",
      "Chao: 40359609687.17476\n",
      "Shlosser: 95367582062.72543\n"
     ]
    }
   ],
   "source": [
    "file1rdd=sc.textFile('/user/zipf/zipf-2-1kww/')\n",
    "begin=time.time()\n",
    "n=file1rdd.count()\n",
    "end=time.time()\n",
    "print(\"count n time:\",end-begin)\n",
    "print(\"n:\",n)\n",
    "width=16\n",
    "q=0.01\n",
    "begin=time.time()\n",
    "part_dict = file1rdd.mapPartitions(TransData)\n",
    "a=part_dict.collect()\n",
    "end=time.time()\n",
    "print(\"Collect Time:\",end-begin)\n",
    "NDVhll=hll(width)\n",
    "for i in a:\n",
    "    NDVhll.update(i[1])\n",
    "NDV=NDVhll.estimate()\n",
    "Part_num=len(a)\n",
    "b=sc.broadcast(pickle.dumps(a))\n",
    "begin=time.time()\n",
    "Aimrdd=sc.parallelize([i for i in range(Part_num)])\n",
    "result=Aimrdd.mapPartitions(partComputef1).collect()\n",
    "f1=sum(result)\n",
    "DGEE=GEE(NDV,f1,q)\n",
    "end=time.time()\n",
    "print(\"GEE Time:\",end-begin)\n",
    "DChao=ModifyChao(NDV,f1)\n",
    "chend=time.time()\n",
    "print(\"Chao Time\",chend-begin)\n",
    "resapfi = sc.parallelize(file1rdd.take(int(n*q))).map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\\\n",
    "    .map(lambda d:(d[1],1)).reduceByKey(lambda e,f:e+f).collect()\n",
    "sampleNDV=0\n",
    "samplef1=0\n",
    "for (key,value) in resapfi:\n",
    "    sampleNDV+=value\n",
    "    if key==1:\n",
    "        samplef1=value\n",
    "DShlosser=NDV+f1*(NDV-sampleNDV)/samplef1\n",
    "shend=time.time()\n",
    "print(\"Shlosser Time:\",end-begin+shend-chend)\n",
    "print(\"d:\",NDV)\n",
    "print(\"f1:\",f1)\n",
    "print(\"GEE:\",DGEE)\n",
    "print(\"Chao:\",DChao)\n",
    "print(\"Shlosser:\",DShlosser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count n time: 78.82403826713562\n",
      "n: 4998045354\n",
      "Collect Time: 135.19188451766968\n",
      "GEE Time: 16.203277826309204\n",
      "Chao Time 16.20352554321289\n",
      "Shlosser Time: 78.31809830665588\n",
      "d: 4932968018.070068\n",
      "f1: 4846064639.790714\n",
      "GEE: 48547549776.18649\n",
      "Chao: 140050512830.065\n",
      "Shlosser: 478560136894.0397\n"
     ]
    }
   ],
   "source": [
    "file1rdd=sc.textFile('/user/zipf/zipf-2-5kww/')\n",
    "begin=time.time()\n",
    "n=file1rdd.count()\n",
    "end=time.time()\n",
    "print(\"count n time:\",end-begin)\n",
    "print(\"n:\",n)\n",
    "width=16\n",
    "q=0.01\n",
    "begin=time.time()\n",
    "part_dict = file1rdd.mapPartitions(TransData)\n",
    "a=part_dict.collect()\n",
    "end=time.time()\n",
    "print(\"Collect Time:\",end-begin)\n",
    "NDVhll=hll(width)\n",
    "for i in a:\n",
    "    NDVhll.update(i[1])\n",
    "NDV=NDVhll.estimate()\n",
    "Part_num=len(a)\n",
    "b=sc.broadcast(pickle.dumps(a))\n",
    "begin=time.time()\n",
    "Aimrdd=sc.parallelize([i for i in range(Part_num)])\n",
    "result=Aimrdd.mapPartitions(partComputef1).collect()\n",
    "f1=sum(result)\n",
    "DGEE=GEE(NDV,f1,q)\n",
    "end=time.time()\n",
    "print(\"GEE Time:\",end-begin)\n",
    "DChao=ModifyChao(NDV,f1)\n",
    "chend=time.time()\n",
    "print(\"Chao Time\",chend-begin)\n",
    "resapfi = sc.parallelize(file1rdd.take(int(n*q))).map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\\\n",
    "    .map(lambda d:(d[1],1)).reduceByKey(lambda e,f:e+f).collect()\n",
    "sampleNDV=0\n",
    "samplef1=0\n",
    "for (key,value) in resapfi:\n",
    "    sampleNDV+=value\n",
    "    if key==1:\n",
    "        samplef1=value\n",
    "DShlosser=NDV+f1*(NDV-sampleNDV)/samplef1\n",
    "shend=time.time()\n",
    "print(\"Shlosser Time:\",end-begin+shend-chend)\n",
    "print(\"d:\",NDV)\n",
    "print(\"f1:\",f1)\n",
    "print(\"GEE:\",DGEE)\n",
    "print(\"Chao:\",DChao)\n",
    "print(\"Shlosser:\",DShlosser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count n time: 153.04342818260193\n",
      "n: 9926629697\n",
      "Collect Time: 238.03894329071045\n",
      "GEE Time: 24.322214603424072\n",
      "Chao Time 24.322423458099365\n",
      "Shlosser Time: 132.2977213859558\n",
      "d: 9819772637.430153\n",
      "f1: 9730099133.778145\n",
      "GEE: 97390664841.43344\n",
      "Chao: 537706072558.57446\n",
      "Shlosser: 962987972922.8815\n"
     ]
    }
   ],
   "source": [
    "file1rdd=sc.textFile('/user/zipf/zipf-2-1www/')\n",
    "begin=time.time()\n",
    "n=file1rdd.count()\n",
    "end=time.time()\n",
    "print(\"count n time:\",end-begin)\n",
    "print(\"n:\",n)\n",
    "width=16\n",
    "q=0.01\n",
    "begin=time.time()\n",
    "part_dict = file1rdd.mapPartitions(TransData)\n",
    "a=part_dict.collect()\n",
    "end=time.time()\n",
    "print(\"Collect Time:\",end-begin)\n",
    "NDVhll=hll(width)\n",
    "for i in a:\n",
    "    NDVhll.update(i[1])\n",
    "NDV=NDVhll.estimate()\n",
    "Part_num=len(a)\n",
    "b=sc.broadcast(pickle.dumps(a))\n",
    "begin=time.time()\n",
    "Aimrdd=sc.parallelize([i for i in range(Part_num)])\n",
    "result=Aimrdd.mapPartitions(partComputef1).collect()\n",
    "f1=sum(result)\n",
    "DGEE=GEE(NDV,f1,q)\n",
    "end=time.time()\n",
    "print(\"GEE Time:\",end-begin)\n",
    "DChao=ModifyChao(NDV,f1)\n",
    "chend=time.time()\n",
    "print(\"Chao Time\",chend-begin)\n",
    "resapfi = sc.parallelize(file1rdd.take(int(n*q))).map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\\\n",
    "    .map(lambda d:(d[1],1)).reduceByKey(lambda e,f:e+f).collect()\n",
    "sampleNDV=0\n",
    "samplef1=0\n",
    "for (key,value) in resapfi:\n",
    "    sampleNDV+=value\n",
    "    if key==1:\n",
    "        samplef1=value\n",
    "DShlosser=NDV+f1*(NDV-sampleNDV)/samplef1\n",
    "shend=time.time()\n",
    "print(\"Shlosser Time:\",end-begin+shend-chend)\n",
    "print(\"d:\",NDV)\n",
    "print(\"f1:\",f1)\n",
    "print(\"GEE:\",DGEE)\n",
    "print(\"Chao:\",DChao)\n",
    "print(\"Shlosser:\",DShlosser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
